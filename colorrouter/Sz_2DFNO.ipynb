{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialize Hyperparameters and import libraries\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from timeit import default_timer\n",
    "import operator\n",
    "from functools import reduce\n",
    "from functools import partial\n",
    "\n",
    "batch_size = 2\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Data\n",
    "\n",
    "n_train = 20000\n",
    "n_test = 1500\n",
    "n_total = n_test+n_train\n",
    "\n",
    "train_structs = np.empty((n_train, 1,  225, 64), np.float32)\n",
    "train_results = np.empty((n_train, 1, 31, 225, 64), np.float32)\n",
    "test_structs = np.empty((n_test, 1, 225, 64), np.float32)\n",
    "test_results = np.empty((n_test, 1, 31, 225, 64),  np.float32)\n",
    "\n",
    "\n",
    "for i in range (n_train):\n",
    "\n",
    "    tmp_struct = np.load(\"D:\\\\Sunghyun Nam\\\\SANZABOO\\\\data_Sz\\\\patternings\\\\patterning_\"+f'{i:08d}'+\".npy\")\n",
    "    tmp_result = np.load(\"D:\\\\Sunghyun Nam\\\\SANZABOO\\\\data_Sz\\\\true_results\\\\result_Sz_\"+f'{i:08d}'+\".npy\")\n",
    "\n",
    "    sampled_result = -1*tmp_result\n",
    "\n",
    "    train_structs[i][0][:15] = np.ones((1*15,64))\n",
    "    train_structs[i][0][15:75] = np.repeat(np.repeat(tmp_struct, 15, axis=0), 2, axis=1)\n",
    "    train_structs[i][0][75:] = np.ones((10*15,64))*2\n",
    "    train_results[i][0] = sampled_result\n",
    "\n",
    "    if i%500 ==0 :\n",
    "        print(i)\n",
    "\n",
    "for i in range (n_test):\n",
    "\n",
    "    tmp_struct = np.load(\"D:\\\\Sunghyun Nam\\\\SANZABOO\\\\data_Sz\\\\patternings\\\\patterning_\"+f'{i+n_train:08d}'+\".npy\")\n",
    "    tmp_result = np.load(\"D:\\\\Sunghyun Nam\\\\SANZABOO\\\\data_Sz\\\\true_results\\\\result_Sz_\"+f'{i+n_train:08d}'+\".npy\")\n",
    "\n",
    "    sampled_result = -1*tmp_result\n",
    "\n",
    "    test_structs[i][0][:15] = np.ones((1*15,64))\n",
    "    test_structs[i][0][15:75] = np.repeat(np.repeat(tmp_struct, 15, axis=0), 2, axis=1)\n",
    "    test_structs[i][0][75:] = np.ones((10*15,64))*2\n",
    "    test_results[i][0] = sampled_result\n",
    "\n",
    "    if i%500 ==0 :\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define 2D FNO Model\n",
    "# Code mostly copied from https://github.com/neuraloperator/neuraloperator/tree/main\n",
    "\n",
    "#Complex multiplication\n",
    "def compl_mul2d(a, b):\n",
    "    op = partial(torch.einsum, \"bixy,ioxy->boxy\")\n",
    "    return torch.stack([\n",
    "        op(a[..., 0], b[..., 0]) - op(a[..., 1], b[..., 1]),\n",
    "        op(a[..., 1], b[..., 0]) + op(a[..., 0], b[..., 1])\n",
    "    ], dim=-1)\n",
    "\n",
    "################################################################\n",
    "# 2D Fourier layer\n",
    "################################################################\n",
    "class SpectralConv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, modes1, modes2):\n",
    "        super(SpectralConv2d, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.modes1 = modes1 #Number of Fourier modes to multiply, at most floor(N/2) + 1\n",
    "        self.modes2 = modes2\n",
    "\n",
    "        self.scale = (1 / (in_channels * out_channels))\n",
    "        self.weights1 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, dtype=torch.cfloat))\n",
    "        self.weights2 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, dtype=torch.cfloat))\n",
    "\n",
    "    # Complex multiplication\n",
    "    def compl_mul2d(self, input, weights):\n",
    "        return torch.einsum(\"bixy,ioxy->boxy\", input, weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batchsize = x.shape[0]\n",
    "        x_ft = torch.fft.rfft2(x)\n",
    "\n",
    "        # Multiply relevant Fourier modes\n",
    "        out_ft = torch.zeros(batchsize, self.out_channels,  x.size(-2), x.size(-1)//2 + 1, dtype=torch.cfloat, device=x.device)\n",
    "        out_ft[:, :, :self.modes1, :self.modes2] = \\\n",
    "            self.compl_mul2d(x_ft[:, :, :self.modes1, :self.modes2], self.weights1)\n",
    "        out_ft[:, :, -self.modes1:, :self.modes2] = \\\n",
    "            self.compl_mul2d(x_ft[:, :, -self.modes1:, :self.modes2], self.weights2)\n",
    "\n",
    "        #Return to physical space\n",
    "        x = torch.fft.irfft2(out_ft, s=(x.size(-2), x.size(-1)))\n",
    "        return x.to(torch.float32)\n",
    "    \n",
    "# 2D FNO Model: input structure output Sz\n",
    "\n",
    "class _2DFNO(nn.Module):\n",
    "    def __init__(self, modes_x, modes_y, width, FNO_layer_num, FC_neuron):\n",
    "        super(_2DFNO, self).__init__()\n",
    "\n",
    "        \"\"\"\n",
    "        The overall network. It contains 4 layers of the Fourier layer.\n",
    "        1. Lift the input to the desire channel dimension by self.fc0 .\n",
    "        2. 4 layers of the integral operators u' = (W + K)(u).\n",
    "            W defined by self.w; K defined by self.conv .\n",
    "        3. Project from the channel space to the output space by self.fc1 and self.fc2 .\n",
    "        \n",
    "        input: the solution of the coefficient function and locations (a(x, y))\n",
    "        input shape: (batchsize, x=s, y=s, c=1)\n",
    "        output: the solution \n",
    "        output shape: (batchsize, c=1)\n",
    "        \"\"\"\n",
    "\n",
    "        # default value 정의\n",
    "        self.modes_x = modes_x\n",
    "        self.modes_y = modes_y\n",
    "        self.width = width\n",
    "        self.FNO_layer_num = FNO_layer_num\n",
    "        self.FC_neuron = FC_neuron\n",
    "        \n",
    "        self.conv_layers = nn.ModuleList([\n",
    "            SpectralConv2d(self.width, self.width, self.modes_x, self.modes_y) for _ in range(self.FNO_layer_num)\n",
    "        ])\n",
    "\n",
    "        self.w_layers = nn.ModuleList([\n",
    "            nn.Conv2d(self.width, self.width, 1) for _ in range(self.FNO_layer_num)\n",
    "        ])\n",
    "        self.fc0 = nn.Linear(1, self.width)\n",
    "\n",
    "        self.fc1_ori = nn.Linear(self.width, self.FC_neuron)\n",
    "        self.fc2_ori = nn.Linear(self.FC_neuron, 31)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = x.permute(0, 2, 3, 1)\n",
    "        x = self.fc0(x)\n",
    "        x = F.gelu(x)\n",
    "        x = x.permute(0, 3, 1, 2) # Batch size, channels\n",
    "\n",
    "        for i in range(self.FNO_layer_num-1):\n",
    "            x1 = self.conv_layers[i](x)\n",
    "            x2 = self.w_layers[i](x)\n",
    "            x = x1 + x2\n",
    "            x = F.gelu(x)\n",
    "\n",
    "        x1 = self.conv_layers[i](x)\n",
    "        x2 = self.w_layers[i](x)\n",
    "        x = x1 + x2\n",
    "\n",
    "        x = x.permute(0, 2, 3, 1)\n",
    "        x = self.fc1_ori(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.fc2_ori(x)\n",
    "\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "\n",
    "        return x.reshape(x.shape[0], 1, 31, x.shape[2], x.shape[3])\n",
    "    \n",
    "    def get_grid(self, shape, device):\n",
    "        batchsize, size_x, size_y = shape[0], shape[1], shape[2]\n",
    "        gridx = torch.tensor(np.linspace(0, 1, size_x), dtype=torch.float)\n",
    "        gridx = gridx.reshape(1, size_x, 1, 1).repeat([batchsize, 1, size_y, 1])\n",
    "        gridy = torch.tensor(np.linspace(0, 1, size_y), dtype=torch.float)\n",
    "        gridy = gridy.reshape(1, 1, size_y, 1).repeat([batchsize, size_x, 1, 1])\n",
    "        return torch.cat((gridx, gridy), dim=-1).to(device)\n",
    "    \n",
    "    def count_params(self):\n",
    "        c = 0\n",
    "        for p in self.parameters():\n",
    "            c += reduce(operator.mul, list(p.size()))\n",
    "        return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training and test data for Ex\n",
    "\n",
    "train_input = torch.tensor(train_structs, dtype=torch.float32)\n",
    "train_output = torch.tensor(train_results, dtype=torch.float32)\n",
    "\n",
    "test_input = torch.tensor(test_structs, dtype=torch.float32)\n",
    "test_output = torch.tensor(test_results, dtype=torch.float32)\n",
    "\n",
    "# train and test loader for model_x\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(train_input, train_output), batch_size=batch_size, shuffle=True)\n",
    "test_loader  = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(test_input, test_output), batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "Train_rmse_arr = [] \n",
    "Test_rmse_arr = []\n",
    "\n",
    "model = _2DFNO(modes_x = 30, modes_y=20, width=32, FNO_layer_num=12, FC_neuron=256).cuda()\n",
    "print(model.count_params())\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.5e-2, weight_decay = 0)\n",
    "\n",
    "step_size = 10\n",
    "gamma = 0.5\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "total_time = 0\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "\n",
    "for ep in range(epochs):\n",
    "    t1 = default_timer()\n",
    "    model.train()\n",
    "    Train_mse = 0\n",
    "    for input_shape, result in train_loader:\n",
    "        input_shape, result  = input_shape.cuda(), result.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(input_shape)\n",
    "        Train_mse_temp = loss(out.reshape(batch_size, -1), result.reshape(batch_size, -1))\n",
    "        Train_mse_temp.backward()\n",
    "        optimizer.step()\n",
    "        Train_mse += np.float64(Train_mse_temp.item())*batch_size\n",
    "    scheduler.step()\n",
    "    \n",
    "    model.eval()\n",
    "    Test_mse = 0.0\n",
    "    with torch.no_grad():\n",
    "        for input_shape, result in test_loader:\n",
    "            input_shape, result  = input_shape.cuda(), result.cuda()\n",
    "            out = model(input_shape)\n",
    "            Test_mse_temp = loss(out.reshape(batch_size, -1), result.reshape(batch_size, -1))\n",
    "            Test_mse += np.float64(Test_mse_temp.item())*batch_size\n",
    "\n",
    "    Train_mse /= n_train\n",
    "    Test_mse /= n_test\n",
    "\n",
    "    Train_rmse = np.sqrt(Train_mse)      \n",
    "    Test_rmse = np.sqrt(Test_mse)\n",
    "\n",
    "    Train_rmse_arr.append(Train_rmse)\n",
    "    Test_rmse_arr.append(Test_rmse)\n",
    "\n",
    "    t2 = default_timer()\n",
    "    print(ep, t2-t1, Train_rmse, Test_rmse)\n",
    "    total_time = total_time + t2 -t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model, \"Sz_2DFNO_20K\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of epochs\n",
    "epochs = len(Train_rmse_arr)\n",
    "epoch_nums = np.arange(1, epochs + 1)  # Array of epoch numbers\n",
    "\n",
    "# Plotting the learning curve for training and test RMSE\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epoch_nums, Train_rmse_arr, label=\"Training RMSE\", color=\"blue\", marker=\"o\")\n",
    "plt.plot(epoch_nums, Test_rmse_arr, label=\"Test RMSE\", color=\"red\", marker=\"x\")\n",
    "\n",
    "# Adding labels, title, and legend\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.title(\"Learning Curve: 400nm\")\n",
    "plt.legend()\n",
    "\n",
    "# Show the grid and plot\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optical Response Function \n",
    "\n",
    "def RGB(field_cell_meent_1d):\n",
    "\n",
    "    res_x = 64\n",
    "\n",
    "    R_index_i = 0\n",
    "    R_index_f = 16\n",
    "    \n",
    "    G_index_i = 16\n",
    "    G_index_f = 32\n",
    "\n",
    "    B_index_i = 32\n",
    "    B_index_f = 48\n",
    "\n",
    "    I_index_i = 48\n",
    "    I_index_f = 64\n",
    "    \n",
    "    B = torch.sum(field_cell_meent_1d[B_index_i:B_index_f])/(0.5*res_x)\n",
    "    G1 = torch.sum(field_cell_meent_1d[G_index_i:G_index_f])/(0.5*res_x)\n",
    "    R = torch.sum(field_cell_meent_1d[R_index_i:R_index_f])/(0.5*res_x)\n",
    "    G2 = torch.sum(field_cell_meent_1d[I_index_i:I_index_f])/(0.5*res_x)\n",
    "\n",
    "    G = G1 + G2\n",
    "\n",
    "    return 4*R, 2*G, 4*B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a random index from the test set\n",
    "n = np.random.randint(0, n_test)\n",
    "\n",
    "# Prepare the sample input and pass it through the model\n",
    "tmp_sample = torch.tensor(np.reshape(test_structs[n], (1, 1, 225, -1)))\n",
    "sample_result = model(tmp_sample.cuda()).cpu().detach().numpy()\n",
    "sample_result = np.squeeze(sample_result)\n",
    "\n",
    "# Create subplots for side-by-side comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))  # 1 row, 2 columns, adjust figure size as needed\n",
    "\n",
    "# Left plot: FNO output\n",
    "im1 = axes[0].imshow(sample_result[0], aspect = 0.4)\n",
    "axes[0].set_title(\"FNO Output\")\n",
    "fig.colorbar(im1, ax=axes[0])\n",
    "\n",
    "# Right plot: True output\n",
    "im2 = axes[1].imshow(test_results[n][0][0], aspect = 0.4)\n",
    "axes[1].set_title(\"True Output\")\n",
    "fig.colorbar(im2, ax=axes[1])\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FNO_time = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FNO_response = []\n",
    "True_response = []\n",
    "t1 = default_timer()\n",
    "for i in range(np.shape(test_results)[2]):\n",
    "    tmp = RGB(torch.tensor(sample_result[i][-1]))\n",
    "    FNO_response.append([tmp[0].numpy(), tmp[1].numpy(), tmp[2].numpy()])\n",
    "t2 = default_timer()\n",
    "\n",
    "print(\"Calculation time via FNO: \", t2-t1)\n",
    "FNO_time.append(t2-t1)\n",
    "for i in range(np.shape(test_results)[2]):\n",
    "    tmp = RGB(torch.tensor(test_results[n][0][i][-1]))\n",
    "    True_response.append([tmp[0].numpy(), tmp[1].numpy(), tmp[2].numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FNO_time = np.array(FNO_time)\n",
    "print(np.average(FNO_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_len_step = 10\n",
    "wav_len_list = [400 + i * wav_len_step for i in range((300) // wav_len_step + 1)]\n",
    "\n",
    "FNO_response = np.array(FNO_response)\n",
    "True_response = np.array(True_response)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.plot(wav_len_list, FNO_response[:,0], label=\"R_FNO\", color=\"r\", marker=\"x\")\n",
    "plt.plot(wav_len_list, FNO_response[:,1], label=\"G_FNO\", color=\"g\", marker=\"x\")\n",
    "plt.plot(wav_len_list, FNO_response[:,2], label=\"B_FNO\", color=\"b\", marker=\"x\")\n",
    "\n",
    "plt.plot(wav_len_list, True_response[:,0], label=\"R_True\", color=\"r\", marker=\"o\")\n",
    "plt.plot(wav_len_list, True_response[:,1], label=\"G_True\", color=\"g\", marker=\"o\")\n",
    "plt.plot(wav_len_list, True_response[:,2], label=\"B_True\", color=\"b\", marker=\"o\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(np.sum(np.abs(FNO_response-True_response))/93)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RGB_abs_err = []\n",
    "\n",
    "for n in range (n_test):\n",
    "\n",
    "    # Prepare the sample input and pass it through the model\n",
    "    tmp_sample = torch.tensor(np.reshape(test_structs[n], (1, 1, 225, -1)))\n",
    "    sample_result = model(tmp_sample.cuda()).cpu().detach().numpy()\n",
    "    sample_result = np.squeeze(sample_result)\n",
    "\n",
    "    FNO_response = []\n",
    "    True_response = []\n",
    "\n",
    "    for i in range(np.shape(test_results)[2]):\n",
    "        tmp = RGB(torch.tensor(sample_result[i][-1]))\n",
    "        FNO_response.append([tmp[0].numpy(), tmp[1].numpy(), tmp[2].numpy()])\n",
    "        tmp = RGB(torch.tensor(test_results[n][0][i][-1]))\n",
    "        True_response.append([tmp[0].numpy(), tmp[1].numpy(), tmp[2].numpy()])\n",
    "    FNO_response = np.array(FNO_response)\n",
    "    True_response = np.array(True_response)\n",
    "\n",
    "    RGB_abs_err.append(np.sum(np.abs(FNO_response-True_response))/93)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RGB_abs_err = np.array(RGB_abs_err)\n",
    "print(np.average(RGB_abs_err))\n",
    "print(np.std(RGB_abs_err))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sunghyunnam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
