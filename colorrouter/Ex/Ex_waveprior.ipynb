{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialize Hyperparameters and import libraries\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from timeit import default_timer\n",
    "import operator\n",
    "from functools import reduce\n",
    "from functools import partial\n",
    "\n",
    "batch_size = 25\n",
    "epochs = 50\n",
    "n_train = 3000\n",
    "n_test = 200\n",
    "n_total = n_train + n_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding wave prior: for details on wave prior, search following paper\n",
    "# https://arxiv.org/abs/2209.10098\n",
    "\n",
    "def wave_prior_y(design_space, wavelength):\n",
    "\n",
    "    del_y_s = 500/15\n",
    "    del_y_d = 1500/60\n",
    "    del_y_p = 500/150\n",
    "\n",
    "    wave_prior = design_space # shape of return is same as design space\n",
    "\n",
    "    for i in range(np.shape(design_space)[0]):\n",
    "        if i<15:\n",
    "            y = del_y_s*i\n",
    "            tmp = 2*np.pi*y/wavelength\n",
    "            wave_prior[i,:] = np.sin(design_space[i,:]*tmp)\n",
    "\n",
    "        elif i<75:\n",
    "            y = del_y_s*15+del_y_d*(i-15)\n",
    "            tmp = 2*np.pi*y/wavelength\n",
    "            wave_prior[i,:] = np.sin(design_space[i,:]*tmp)\n",
    "\n",
    "        else:\n",
    "            y = del_y_s*15+del_y_d*60 + del_y_p*(i-65)\n",
    "            tmp = 2*np.pi*y/wavelength\n",
    "            wave_prior[i,:] = np.sin(design_space[i,:]*tmp)\n",
    "\n",
    "    return wave_prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wave_prior_x(design_space, wavelength):\n",
    "\n",
    "    del_x = 1000/32\n",
    "    \n",
    "    wave_prior = design_space # shape of return is same as design space\n",
    "\n",
    "    for i in range(np.shape(design_space)[1]):\n",
    "        x = del_x*i\n",
    "        tmp = 2*np.pi*x/wavelength\n",
    "        wave_prior[:,i] = np.sin(design_space[:,i]*tmp)\n",
    "\n",
    "    return wave_prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check wave prior implementation\n",
    "\n",
    "very_tmp = np.load(\"D:\\\\Sunghyun Nam\\\\SANZABOO\\\\data_Ez_Fermi\\\\data_Ez\\\\patternings\\\\patterning_\"+f'{2:08d}'+\".npy\")\n",
    "tmp_wl = 500\n",
    "tmp_sv = np.empty((225,64))\n",
    "tmp_sv[:15] = np.ones((1*15,64))\n",
    "tmp_sv[15:75] = np.repeat(np.repeat(very_tmp, 15, axis=0), 2, axis=1)\n",
    "tmp_sv[75:] = np.ones((10*15,64))*2\n",
    "\n",
    "plt.imshow(wave_prior_y(tmp_sv, tmp_wl), aspect=0.4)\n",
    "plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Data: Train\n",
    "\n",
    "wav_len_step = 10\n",
    "wav_len_list = [400 + i * wav_len_step for i in range((300) // wav_len_step + 1)]\n",
    "wl_list_train = wav_len_list\n",
    "n_wl_train = len(wl_list_train)\n",
    "\n",
    "train_wprior  = np.empty((n_train*n_wl_train, 1, 225, 64), np.float32)\n",
    "train_results = np.empty((n_train*n_wl_train, 2, 225, 64), np.float32)\n",
    "\n",
    "for i in range (n_train):\n",
    "\n",
    "    tmp_struct = np.load(\"D:\\\\Sunghyun Nam\\\\SANZABOO\\\\data_Ez_Fermi\\\\data_Ez\\\\patternings\\\\patterning_\"+f'{i:08d}'+\".npy\")\n",
    "    tmp_result = np.load(\"D:\\\\Sunghyun Nam\\\\SANZABOO\\\\data_Ez_Fermi\\\\data_Ez\\\\true_results\\\\result_Ex_\"+f'{i:08d}'+\".npy\")\n",
    "\n",
    "    sampled_result = tmp_result\n",
    "\n",
    "    train_space = np.empty((225,64))\n",
    "    train_space[:15] = np.ones((1*15,64))\n",
    "    train_space[15:75] = np.repeat(np.repeat(tmp_struct, 15, axis=0), 2, axis=1)\n",
    "    train_space[75:] = np.ones((10*15,64))*2\n",
    "\n",
    "    for k in range(n_wl_train):\n",
    "        \n",
    "        tmp_wl = wl_list_train[k]\n",
    "\n",
    "        train_wprior[i*n_wl_train + k][0] = wave_prior_y(np.copy(train_space), tmp_wl) # y waveprior\n",
    "        #train_wprior[i*n_wl + k][1] = wave_prior_x(tmp_sv, wl_list[k]) # x waveprior\n",
    "        train_results[i*n_wl_train + k][0] = np.real(sampled_result[k])\n",
    "        train_results[i*n_wl_train + k][1] = np.imag(sampled_result[k])\n",
    "\n",
    "    if i%500 ==0 :\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Data: Test\n",
    "\n",
    "wl_list_test = wav_len_list\n",
    "n_wl_test = len(wl_list_test)\n",
    "\n",
    "test_wprior   = np.empty((n_test*n_wl_test, 1, 225, 64), np.float32)\n",
    "test_results  = np.empty((n_test*n_wl_test, 2, 225, 64), np.float32)\n",
    "\n",
    "for i in range (n_test):\n",
    "\n",
    "    tmp_struct = np.load(\"D:\\\\Sunghyun Nam\\\\SANZABOO\\\\data_Ez\\\\patternings\\\\patterning_\"+f'{i:08d}'+\".npy\")\n",
    "    tmp_result = np.load(\"D:\\\\Sunghyun Nam\\\\SANZABOO\\\\data_Ez\\\\true_results\\\\result_Ex_\"+f'{i:08d}'+\".npy\")\n",
    "\n",
    "    sampled_result = tmp_result\n",
    "\n",
    "    test_space = np.empty((225,64))\n",
    "    test_space[:15] = np.ones((1*15,64))\n",
    "    test_space[15:75] = np.repeat(np.repeat(tmp_struct, 15, axis=0), 2, axis=1)\n",
    "    test_space[75:] = np.ones((10*15,64))*2\n",
    "\n",
    "    for k in range(n_wl_test):\n",
    "\n",
    "        tmp_wl = wl_list_test[k]\n",
    "\n",
    "        test_wprior[i*n_wl_test + k] = wave_prior_y(np.copy(test_space), tmp_wl) # y waveprior\n",
    "        #train_wprior[i*n_wl + k][1] = wave_prior_x(tmp_sv, wl_list[k]) # x waveprior\n",
    "\n",
    "        test_results[i*n_wl_test + k][0] = np.real(sampled_result[k])\n",
    "        test_results[i*n_wl_test + k][1] = np.imag(sampled_result[k])\n",
    "\n",
    "    if i%500 ==0 :\n",
    "        print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define 2D FNO Model\n",
    "# Code mostly copied from https://github.com/neuraloperator/neuraloperator/tree/main\n",
    "\n",
    "#Complex multiplication\n",
    "def compl_mul2d(a, b):\n",
    "    # (batch, in_channel, x,y ), (in_channel, out_channel, x,y) -> (batch, out_channel, x,y)\n",
    "    op = partial(torch.einsum, \"bixy,ioxy->boxy\")\n",
    "    return torch.stack([\n",
    "        op(a[..., 0], b[..., 0]) - op(a[..., 1], b[..., 1]),\n",
    "        op(a[..., 1], b[..., 0]) + op(a[..., 0], b[..., 1])\n",
    "    ], dim=-1)\n",
    "\n",
    "################################################################\n",
    "# 2D Fourier layer\n",
    "################################################################\n",
    "class SpectralConv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, modes1, modes2):\n",
    "        super(SpectralConv2d, self).__init__()\n",
    "\n",
    "        \"\"\"\n",
    "        2D Fourier layer. It does FFT, linear transform, and Inverse FFT.    \n",
    "        \"\"\"\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.modes1 = modes1 #Number of Fourier modes to multiply, at most floor(N/2) + 1\n",
    "        self.modes2 = modes2\n",
    "\n",
    "        self.scale = (1 / (in_channels * out_channels))\n",
    "        self.weights1 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, dtype=torch.cfloat))\n",
    "        self.weights2 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, dtype=torch.cfloat))\n",
    "\n",
    "    # Complex multiplication\n",
    "    def compl_mul2d(self, input, weights):\n",
    "        return torch.einsum(\"bixy,ioxy->boxy\", input, weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batchsize = x.shape[0]\n",
    "        x_ft = torch.fft.rfft2(x)\n",
    "\n",
    "        # Multiply relevant Fourier modes\n",
    "        out_ft = torch.zeros(batchsize, self.out_channels,  x.size(-2), x.size(-1)//2 + 1, dtype=torch.cfloat, device=x.device)\n",
    "        out_ft[:, :, :self.modes1, :self.modes2] = \\\n",
    "            self.compl_mul2d(x_ft[:, :, :self.modes1, :self.modes2], self.weights1)\n",
    "        out_ft[:, :, -self.modes1:, :self.modes2] = \\\n",
    "            self.compl_mul2d(x_ft[:, :, -self.modes1:, :self.modes2], self.weights2)\n",
    "\n",
    "        #Return to physical space\n",
    "        x = torch.fft.irfft2(out_ft, s=(x.size(-2), x.size(-1)))\n",
    "        return x.to(torch.float32)\n",
    "\n",
    "# 2D FNO Model: input wave prior, output Ex\n",
    "\n",
    "class _2DFNO(nn.Module):\n",
    "    def __init__(self, modes_x, modes_y, width, FNO_layer_num, FC_neuron):\n",
    "        super(_2DFNO, self).__init__()\n",
    "\n",
    "        self.modes_x = modes_x\n",
    "        self.modes_y = modes_y\n",
    "        self.width = width\n",
    "        self.FNO_layer_num = FNO_layer_num\n",
    "        self.FC_neuron = FC_neuron\n",
    "        \n",
    "        self.conv_layers = nn.ModuleList([\n",
    "            SpectralConv2d(self.width, self.width, self.modes_x, self.modes_y) for _ in range(self.FNO_layer_num)\n",
    "        ])\n",
    "\n",
    "        self.w_layers = nn.ModuleList([\n",
    "            nn.Conv2d(self.width, self.width, 1) for _ in range(self.FNO_layer_num)\n",
    "        ])\n",
    "        self.fc0 = nn.Linear(1, self.width)\n",
    "\n",
    "        self.fc1_ori = nn.Linear(self.width, self.FC_neuron)\n",
    "        self.fc2_ori = nn.Linear(self.FC_neuron, 2)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "\n",
    "        x = x.permute(0, 2, 3, 1)\n",
    "        #grid = self.get_grid(x.shape, x.device)\n",
    "        x = self.fc0(x)\n",
    "        x = F.gelu(x)\n",
    "        x = x.permute(0, 3, 1, 2) # Batch size, channels\n",
    "\n",
    "        for i in range(self.FNO_layer_num-1):\n",
    "            x1 = self.conv_layers[i](x)\n",
    "            x2 = self.w_layers[i](x)\n",
    "            x = x1 + x2\n",
    "            x = F.gelu(x)\n",
    "\n",
    "        x1 = self.conv_layers[i](x)\n",
    "        x2 = self.w_layers[i](x)\n",
    "        x = x1 + x2\n",
    "\n",
    "        x = x.permute(0, 2, 3, 1)\n",
    "        x = self.fc1_ori(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.fc2_ori(x)\n",
    "\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def get_grid(self, shape, device):\n",
    "        batchsize, size_x, size_y = shape[0], shape[1], shape[2]\n",
    "        gridx = torch.tensor(np.linspace(0, 1, size_x), dtype=torch.float)\n",
    "        gridx = gridx.reshape(1, size_x, 1, 1).repeat([batchsize, 1, size_y, 1])\n",
    "        gridy = torch.tensor(np.linspace(0, 1, size_y), dtype=torch.float)\n",
    "        gridy = gridy.reshape(1, 1, size_y, 1).repeat([batchsize, size_x, 1, 1])\n",
    "        return torch.cat((gridx, gridy), dim=-1).to(device)\n",
    "    \n",
    "    def count_params(self):\n",
    "        c = 0\n",
    "        for p in self.parameters():\n",
    "            c += reduce(operator.mul, list(p.size()))\n",
    "        return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training and test data for Ex\n",
    "\n",
    "train_input = torch.tensor(train_wprior, dtype=torch.float32)\n",
    "train_output = torch.tensor(train_results, dtype=torch.float32)\n",
    "\n",
    "test_input = torch.tensor(test_wprior, dtype=torch.float32)\n",
    "test_output = torch.tensor(test_results, dtype=torch.float32)\n",
    "\n",
    "# train and test loader for model_x\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(train_input, train_output), batch_size=batch_size, shuffle=True)\n",
    "test_loader  = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(test_input, test_output), batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "\n",
    "model = _2DFNO(modes_x=32, modes_y=15, width=10, FNO_layer_num=4, FC_neuron=64).cuda()\n",
    "print(f\"Total parameters in the model: {model.count_params()}\")\n",
    "\n",
    "# Optimizer and scheduler\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.5e-2, weight_decay=0)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)\n",
    "\n",
    "# Loss function\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# Track training and testing RMSE over time\n",
    "Train_rmse_arr = [] \n",
    "Test_rmse_arr = []\n",
    "\n",
    "# Free up GPU memory before starting training\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Training loop\n",
    "total_time = 0\n",
    "\n",
    "for ep in range(epochs):\n",
    "    t1 = default_timer()\n",
    "    model.train()\n",
    "    Train_mse = 0\n",
    "\n",
    "    for input_shape, result in train_loader:\n",
    "        input_shape, result = input_shape.cuda(), result.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass through the model with the hypernetwork\n",
    "        out = model(input_shape)\n",
    "        \n",
    "        # Calculate loss\n",
    "        Train_mse_temp = loss_fn(out.reshape(batch_size, -1), result.reshape(batch_size, -1))\n",
    "        torch.cuda.empty_cache()\n",
    "        Train_mse_temp.backward()\n",
    "        \n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        Train_mse += Train_mse_temp.item() * batch_size\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    Test_mse = 0.0\n",
    "    with torch.no_grad():\n",
    "        for input_shape, result in test_loader:\n",
    "            input_shape, result = input_shape.cuda(), result.cuda()\n",
    "\n",
    "            # Forward pass through the model during testing\n",
    "            out = model(input_shape)\n",
    "            Test_mse_temp = loss_fn(out.reshape(batch_size, -1), result.reshape(batch_size, -1))\n",
    "            Test_mse += Test_mse_temp.item() * batch_size\n",
    "\n",
    "    # Compute RMSE for train and test sets\n",
    "    Train_mse /= len(train_loader.dataset)\n",
    "    Test_mse /= len(test_loader.dataset)\n",
    "\n",
    "    Train_rmse = np.sqrt(Train_mse)\n",
    "    Test_rmse = np.sqrt(Test_mse)\n",
    "\n",
    "    # Store RMSE values for each epoch\n",
    "    Train_rmse_arr.append(Train_rmse)\n",
    "    Test_rmse_arr.append(Test_rmse)\n",
    "\n",
    "    t2 = default_timer()\n",
    "    total_time += t2 - t1\n",
    "\n",
    "    print(f\"Epoch {ep+1}, Time: {t2-t1:.2f}s, Train RMSE: {Train_rmse:.4f}, Test RMSE: {Test_rmse:.4f}\")\n",
    "\n",
    "# Training complete\n",
    "print(f\"Training completed in {total_time:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of epochs\n",
    "epochs = len(Train_rmse_arr)\n",
    "epoch_nums = np.arange(1, epochs + 1)  # Array of epoch numbers\n",
    "\n",
    "# Plotting the learning curve for training and test RMSE\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epoch_nums, Train_rmse_arr, label=\"Training RMSE\", color=\"blue\", marker=\"o\")\n",
    "plt.plot(epoch_nums, Test_rmse_arr, label=\"Test RMSE\", color=\"red\", marker=\"x\")\n",
    "\n",
    "# Adding labels, title, and legend\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.title(\"Learning Curve: 400nm\")\n",
    "plt.legend()\n",
    "\n",
    "# Show the grid and plot\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a random index from the test set\n",
    "n = np.random.randint(0, n_test)\n",
    "\n",
    "# Prepare the sample input and pass it through the model\n",
    "tmp_sample = torch.tensor(np.reshape(test_wprior[n], (1, 1, 225, -1)))\n",
    "sample_result = model(tmp_sample.cuda()).cpu().detach().numpy()\n",
    "sample_result = np.squeeze(sample_result)\n",
    "\n",
    "# Create subplots for side-by-side comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))  # 1 row, 2 columns, adjust figure size as needed\n",
    "\n",
    "# Left plot: FNO output\n",
    "im1 = axes[0].imshow(sample_result[0], aspect = 0.4)\n",
    "axes[0].set_title(\"FNO Output\")\n",
    "fig.colorbar(im1, ax=axes[0])\n",
    "\n",
    "# Right plot: True output\n",
    "im2 = axes[1].imshow(test_results[n][0], aspect = 0.4)\n",
    "axes[1].set_title(\"True Output\")\n",
    "fig.colorbar(im2, ax=axes[1])\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sunghyunnam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
